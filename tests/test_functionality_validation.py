#!/usr/bin/env python3
"""
Functionality Validation Test Suite

Validates that all the enhanced chat and workflow functionality has been properly implemented
without requiring complex authentication or full system integration.
"""

import asyncio
import json
import time
import sys
from datetime import datetime
from pathlib import Path

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from monitoring_dashboard import MonitoringDashboard


class FunctionalityValidator:
    """Validates implementation of enhanced dashboard functionality"""

    def __init__(self):
        self.test_results = []
        self.validation_time = datetime.now().isoformat()

    async def run_all_validations(self):
        """Run comprehensive functionality validation"""
        print("ðŸ” Functionality Validation Test Suite")
        print("=" * 50)
        print("Validating implementation completeness...\n")

        validations = [
            self.validate_dashboard_initialization,
            self.validate_workflow_detection_logic,
            self.validate_workflow_templates,
            self.validate_api_endpoint_definitions,
            self.validate_enhanced_chat_structure,
            self.validate_navigation_system,
            self.validate_file_upload_handling,
            self.validate_workflow_execution_logic,
            self.validate_security_implementation,
            self.validate_error_handling
        ]

        for validation in validations:
            try:
                await validation()
            except Exception as e:
                print(f"âŒ Validation failed: {e}")
                self.test_results.append({
                    "validation": validation.__name__,
                    "success": False,
                    "error": str(e)
                })

        await self.generate_validation_report()

    async def validate_dashboard_initialization(self):
        """Validate that dashboard initializes with enhanced features"""
        print("ðŸš€ Validating Dashboard Initialization")

        try:
            # Create dashboard instance
            dashboard = MonitoringDashboard(port=8090)

            # Check enhanced attributes are initialized
            validations = [
                ("chat_sessions", hasattr(dashboard, 'chat_sessions')),
                ("scheduled_workflows", hasattr(dashboard, 'scheduled_workflows')),
                ("chat_messages", hasattr(dashboard, 'chat_messages')),
                ("workflow_sessions", hasattr(dashboard, 'workflow_sessions'))
            ]

            for attr_name, has_attr in validations:
                if has_attr:
                    print(f"  âœ… {attr_name}: initialized")
                else:
                    print(f"  âŒ {attr_name}: missing")

            # Check route definitions
            expected_routes = [
                '/api/chat/sessions',
                '/api/workflows/start',
                '/api/workflows/schedule',
                '/api/scheduled-workflows',
                '/api/upload',
                '/dashboard/simple',
                '/dashboard/enhanced',
                '/dashboard/charts',
                '/dashboard/advanced',
                '/dashboard/nav'
            ]

            route_count = len(dashboard.app.router.routes())
            print(f"  âœ… Total routes configured: {route_count}")

            # Check specific route existence
            missing_routes = []
            for expected_route in expected_routes:
                route_found = False
                for route in dashboard.app.router.routes():
                    if expected_route in str(route.resource):
                        route_found = True
                        break

                if route_found:
                    print(f"  âœ… Route found: {expected_route}")
                else:
                    print(f"  âŒ Route missing: {expected_route}")
                    missing_routes.append(expected_route)

            success = len(missing_routes) == 0 and all(has_attr for _, has_attr in validations)

            self.test_results.append({
                "validation": "dashboard_initialization",
                "success": success,
                "routes_configured": route_count,
                "missing_routes": len(missing_routes),
                "enhanced_attributes_initialized": all(has_attr for _, has_attr in validations)
            })

        except Exception as e:
            print(f"  âŒ Dashboard initialization validation failed: {e}")
            self.test_results.append({
                "validation": "dashboard_initialization",
                "success": False,
                "error": str(e)
            })

    async def validate_workflow_detection_logic(self):
        """Validate workflow detection algorithms"""
        print("\nðŸ¤– Validating Workflow Detection Logic")

        try:
            # Test the detect_workflows_in_message method exists and works
            dashboard = MonitoringDashboard(port=8091)

            # Test cases for workflow detection
            test_cases = [
                {
                    "message": "I need to implement a new feature",
                    "expected_workflow": "feature-development",
                    "description": "Feature development detection"
                },
                {
                    "message": "Perform a security audit",
                    "expected_workflow": "security-audit",
                    "description": "Security audit detection"
                },
                {
                    "message": "Update documentation",
                    "expected_workflow": "documentation-update",
                    "description": "Documentation update detection"
                },
                {
                    "message": "Debug this issue",
                    "expected_workflow": "debugging-session",
                    "description": "Debugging session detection"
                },
                {
                    "message": "Prepare for deployment",
                    "expected_workflow": "deployment-prep",
                    "description": "Deployment preparation detection"
                }
            ]

            detection_results = []

            for test_case in test_cases:
                # Test the detection logic exists
                has_detection_method = hasattr(dashboard, 'detect_workflows_in_message')

                if has_detection_method:
                    # Test detection logic
                    detected = await dashboard.detect_workflows_in_message(test_case["message"])
                    workflow_detected = len(detected) > 0
                    expected_detected = test_case["expected_workflow"] in [w["workflow_id"] for w in detected]

                    detection_results.append({
                        "test": test_case["description"],
                        "success": expected_detected,
                        "expected": test_case["expected_workflow"],
                        "detected": [w["workflow_id"] for w in detected] if workflow_detected else []
                    })

                    status = "âœ…" if expected_detected else "âŒ"
                    print(f"  {status} {test_case['description']}")
                else:
                    print(f"  âŒ Detection method not found")
                    detection_results.append({
                        "test": test_case["description"],
                        "success": False,
                        "error": "Detection method not found"
                    })

            success_count = sum(1 for r in detection_results if r["success"])
            total_tests = len(detection_results)
            success_rate = (success_count / total_tests) * 100 if total_tests > 0 else 0

            print(f"  ðŸ“Š Detection Success Rate: {success_rate:.1f}%")

            self.test_results.append({
                "validation": "workflow_detection_logic",
                "success": success_rate >= 80,
                "detection_method_exists": has_detection_method,
                "success_rate": success_rate,
                "tests_passed": success_count,
                "total_tests": total_tests
            })

        except Exception as e:
            print(f"  âŒ Workflow detection validation failed: {e}")
            self.test_results.append({
                "validation": "workflow_detection_logic",
                "success": False,
                "error": str(e)
            })

    async def validate_workflow_templates(self):
        """Validate workflow template definitions"""
        print("\nðŸ“‹ Validating Workflow Templates")

        try:
            dashboard = MonitoringDashboard(port=8092)

            # Check get_workflow_phases method exists
            has_workflow_phases = hasattr(dashboard, 'get_workflow_phases')

            if has_workflow_phases:
                expected_workflows = [
                    "feature-development",
                    "security-audit",
                    "documentation-update",
                    "debugging-session",
                    "deployment-prep"
                ]

                workflow_validation = []

                for workflow_id in expected_workflows:
                    phases = dashboard.get_workflow_phases(workflow_id)

                    if phases and len(phases) > 0:
                        phase_count = len(phases)
                        has_agents = all('agents' in phase_data for phase_data in phases.values())
                        has_descriptions = all('description' in phase_data for phase_data in phases.values())

                        workflow_validation.append({
                            "workflow_id": workflow_id,
                            "success": True,
                            "phases": phase_count,
                            "has_agents": has_agents,
                            "has_descriptions": has_descriptions
                        })

                        print(f"  âœ… {workflow_id}: {phase_count} phases, agents: {has_agents}")
                    else:
                        workflow_validation.append({
                            "workflow_id": workflow_id,
                            "success": False,
                            "error": "No phases defined"
                        })
                        print(f"  âŒ {workflow_id}: No phases defined")

                success_count = sum(1 for v in workflow_validation if v["success"])
                success_rate = (success_count / len(expected_workflows)) * 100

                self.test_results.append({
                    "validation": "workflow_templates",
                    "success": success_rate == 100,
                    "workflow_phases_method_exists": True,
                    "success_rate": success_rate,
                    "workflows_validated": success_count,
                    "total_workflows": len(expected_workflows)
                })

            else:
                print("  âŒ get_workflow_phases method not found")
                self.test_results.append({
                    "validation": "workflow_templates",
                    "success": False,
                    "error": "get_workflow_phases method missing"
                })

        except Exception as e:
            print(f"  âŒ Workflow templates validation failed: {e}")
            self.test_results.append({
                "validation": "workflow_templates",
                "success": False,
                "error": str(e)
            })

    async def validate_api_endpoint_definitions(self):
        """Validate that all required API endpoints are defined"""
        print("\nðŸ”— Validating API Endpoint Definitions")

        try:
            dashboard = MonitoringDashboard(port=8093)

            # Check API endpoint methods exist
            required_endpoints = [
                ('get_chat_sessions', '/api/chat/sessions'),
                ('start_workflow_api', '/api/workflows/start'),
                ('schedule_workflow_api', '/api/workflows/schedule'),
                ('get_scheduled_workflows', '/api/scheduled-workflows'),
                ('handle_file_upload_api', '/api/upload')
            ]

            endpoint_validation = []

            for method_name, endpoint_path in required_endpoints:
                has_method = hasattr(dashboard, method_name)

                if has_method:
                    # Check if method is callable
                    method = getattr(dashboard, method_name)
                    is_callable = callable(method)

                    endpoint_validation.append({
                        "endpoint": endpoint_path,
                        "method_name": method_name,
                        "success": is_callable,
                        "callable": is_callable
                    })

                    status = "âœ…" if is_callable else "âŒ"
                    print(f"  {status} {endpoint_path} ({method_name})")
                else:
                    endpoint_validation.append({
                        "endpoint": endpoint_path,
                        "method_name": method_name,
                        "success": False,
                        "error": "Method not found"
                    })
                    print(f"  âŒ {endpoint_path} ({method_name}): Method not found")

            success_count = sum(1 for v in endpoint_validation if v["success"])
            success_rate = (success_count / len(required_endpoints)) * 100

            self.test_results.append({
                "validation": "api_endpoint_definitions",
                "success": success_rate == 100,
                "success_rate": success_rate,
                "endpoints_defined": success_count,
                "total_endpoints": len(required_endpoints)
            })

        except Exception as e:
            print(f"  âŒ API endpoint validation failed: {e}")
            self.test_results.append({
                "validation": "api_endpoint_definitions",
                "success": False,
                "error": str(e)
            })

    async def validate_enhanced_chat_structure(self):
        """Validate enhanced chat structure and methods"""
        print("\nðŸ’¬ Validating Enhanced Chat Structure")

        try:
            dashboard = MonitoringDashboard(port=8094)

            # Check enhanced chat methods
            required_chat_methods = [
                'handle_enhanced_chat_message',
                'generate_workflow_suggestions',
                'generate_general_response',
                'handle_session_management',
                'handle_file_upload'
            ]

            chat_method_validation = []

            for method_name in required_chat_methods:
                has_method = hasattr(dashboard, method_name)

                if has_method:
                    method = getattr(dashboard, method_name)
                    is_callable = callable(method)

                    chat_method_validation.append({
                        "method_name": method_name,
                        "success": is_callable,
                        "callable": is_callable
                    })

                    status = "âœ…" if is_callable else "âŒ"
                    print(f"  {status} {method_name}")
                else:
                    chat_method_validation.append({
                        "method_name": method_name,
                        "success": False,
                        "error": "Method not found"
                    })
                    print(f"  âŒ {method_name}: Method not found")

            # Check chat data structures
            has_chat_sessions = hasattr(dashboard, 'chat_sessions')
            has_chat_messages = hasattr(dashboard, 'chat_messages')

            print(f"  {'âœ…' if has_chat_sessions else 'âŒ'} chat_sessions: {'initialized' if has_chat_sessions else 'missing'}")
            print(f"  {'âœ…' if has_chat_messages else 'âŒ'} chat_messages: {'initialized' if has_chat_messages else 'missing'}")

            method_success_count = sum(1 for v in chat_method_validation if v["success"])
            method_success_rate = (method_success_count / len(required_chat_methods)) * 100
            structure_success = has_chat_sessions and has_chat_messages

            self.test_results.append({
                "validation": "enhanced_chat_structure",
                "success": method_success_rate >= 80 and structure_success,
                "method_success_rate": method_success_rate,
                "methods_implemented": method_success_count,
                "total_methods": len(required_chat_methods),
                "chat_sessions_initialized": has_chat_sessions,
                "chat_messages_initialized": has_chat_messages
            })

        except Exception as e:
            print(f"  âŒ Enhanced chat structure validation failed: {e}")
            self.test_results.append({
                "validation": "enhanced_chat_structure",
                "success": False,
                "error": str(e)
            })

    async def validate_navigation_system(self):
        """Validate navigation system implementation"""
        print("\nðŸ§­ Validating Navigation System")

        try:
            dashboard = MonitoringDashboard(port=8095)

            # Check navigation methods
            navigation_methods = [
                ('serve_simple_dashboard', '/dashboard/simple'),
                ('serve_enhanced_dashboard', '/dashboard/enhanced'),
                ('serve_charts_dashboard', '/dashboard/charts'),
                ('serve_advanced_dashboard', '/dashboard/advanced'),
                ('serve_navigation', '/dashboard/nav')
            ]

            navigation_validation = []

            for method_name, expected_path in navigation_methods:
                has_method = hasattr(dashboard, method_name)

                if has_method:
                    method = getattr(dashboard, method_name)
                    is_callable = callable(method)

                    navigation_validation.append({
                        "path": expected_path,
                        "method_name": method_name,
                        "success": is_callable
                    })

                    status = "âœ…" if is_callable else "âŒ"
                    print(f"  {status} {expected_path} ({method_name})")
                else:
                    navigation_validation.append({
                        "path": expected_path,
                        "method_name": method_name,
                        "success": False
                    })
                    print(f"  âŒ {expected_path} ({method_name}): Method not found")

            success_count = sum(1 for v in navigation_validation if v["success"])
            success_rate = (success_count / len(navigation_methods)) * 100

            # Check navigation page generation method
            has_navigation_page = hasattr(dashboard, 'get_navigation_page')
            print(f"  {'âœ…' if has_navigation_page else 'âŒ'} Navigation page generator: {'found' if has_navigation_page else 'missing'}")

            self.test_results.append({
                "validation": "navigation_system",
                "success": success_rate >= 80 and has_navigation_page,
                "success_rate": success_rate,
                "navigation_methods": success_count,
                "total_methods": len(navigation_methods),
                "has_navigation_page": has_navigation_page
            })

        except Exception as e:
            print(f"  âŒ Navigation system validation failed: {e}")
            self.test_results.append({
                "validation": "navigation_system",
                "success": False,
                "error": str(e)
            })

    async def validate_file_upload_handling(self):
        """Validate file upload handling implementation"""
        print("\nðŸ“ Validating File Upload Handling")

        try:
            dashboard = MonitoringDashboard(port=8096)

            # Check file upload methods
            file_methods = [
                'handle_file_upload',
                'handle_file_upload_api'
            ]

            file_method_validation = []

            for method_name in file_methods:
                has_method = hasattr(dashboard, method_name)

                if has_method:
                    method = getattr(dashboard, method_name)
                    is_callable = callable(method)

                    file_method_validation.append({
                        "method_name": method_name,
                        "success": is_callable
                    })

                    status = "âœ…" if is_callable else "âŒ"
                    print(f"  {status} {method_name}")
                else:
                    file_method_validation.append({
                        "method_name": method_name,
                        "success": False
                    })
                    print(f"  âŒ {method_name}: Method not found")

            success_count = sum(1 for v in file_method_validation if v["success"])
            success_rate = (success_count / len(file_methods)) * 100

            # Check API route exists
            api_route_exists = False
            for route in dashboard.app.router.routes():
                if '/api/upload' in str(route.resource):
                    api_route_exists = True
                    break

            print(f"  {'âœ…' if api_route_exists else 'âŒ'} /api/upload route: {'configured' if api_route_exists else 'missing'}")

            self.test_results.append({
                "validation": "file_upload_handling",
                "success": success_rate >= 50 and api_route_exists,
                "method_success_rate": success_rate,
                "methods_implemented": success_count,
                "total_methods": len(file_methods),
                "api_route_configured": api_route_exists
            })

        except Exception as e:
            print(f"  âŒ File upload validation failed: {e}")
            self.test_results.append({
                "validation": "file_upload_handling",
                "success": False,
                "error": str(e)
            })

    async def validate_workflow_execution_logic(self):
        """Validate workflow execution logic"""
        print("\nâš™ï¸ Validating Workflow Execution Logic")

        try:
            dashboard = MonitoringDashboard(port=8097)

            # Check workflow execution methods
            execution_methods = [
                'execute_workflow',
                'schedule_workflow_execution',
                'handle_workflow_assignment',
                'handle_workflow_scheduling'
            ]

            execution_validation = []

            for method_name in execution_methods:
                has_method = hasattr(dashboard, method_name)

                if has_method:
                    method = getattr(dashboard, method_name)
                    is_callable = callable(method)

                    execution_validation.append({
                        "method_name": method_name,
                        "success": is_callable
                    })

                    status = "âœ…" if is_callable else "âŒ"
                    print(f"  {status} {method_name}")
                else:
                    execution_validation.append({
                        "method_name": method_name,
                        "success": False
                    })
                    print(f"  âŒ {method_name}: Method not found")

            success_count = sum(1 for v in execution_validation if v["success"])
            success_rate = (success_count / len(execution_methods)) * 100

            # Check workflow sessions handling
            has_workflow_sessions = hasattr(dashboard, 'workflow_sessions')
            has_scheduled_workflows = hasattr(dashboard, 'scheduled_workflows')

            print(f"  {'âœ…' if has_workflow_sessions else 'âŒ'} workflow_sessions: {'initialized' if has_workflow_sessions else 'missing'}")
            print(f"  {'âœ…' if has_scheduled_workflows else 'âŒ'} scheduled_workflows: {'initialized' if has_scheduled_workflows else 'missing'}")

            self.test_results.append({
                "validation": "workflow_execution_logic",
                "success": success_rate >= 75 and has_workflow_sessions,
                "method_success_rate": success_rate,
                "methods_implemented": success_count,
                "total_methods": len(execution_methods),
                "workflow_sessions_initialized": has_workflow_sessions,
                "scheduled_workflows_initialized": has_scheduled_workflows
            })

        except Exception as e:
            print(f"  âŒ Workflow execution validation failed: {e}")
            self.test_results.append({
                "validation": "workflow_execution_logic",
                "success": False,
                "error": str(e)
            })

    async def validate_security_implementation(self):
        """Validate security implementation"""
        print("\nðŸ”’ Validating Security Implementation")

        try:
            dashboard = MonitoringDashboard(port=8098)

            # Check password protection
            has_password = hasattr(dashboard, 'password')
            has_auth_token = hasattr(dashboard, 'auth_token')

            print(f"  {'âœ…' if has_password else 'âŒ'} Password protection: {'enabled' if has_password else 'disabled'}")
            print(f"  {'âœ…' if has_auth_token else 'âŒ'} Authentication token: {'initialized' if has_auth_token else 'missing'}")

            # Check authentication middleware
            has_auth_middleware = hasattr(dashboard, 'setup_auth_middleware')

            print(f"  {'âœ…' if has_auth_middleware else 'âŒ'} Auth middleware: {'configured' if has_auth_middleware else 'missing'}")

            # Check CORS setup
            has_cors = hasattr(dashboard, 'setup_cors')

            print(f"  {'âœ…' if has_cors else 'âŒ'} CORS setup: {'configured' if has_cors else 'missing'}")

            security_score = sum([
                has_password,
                has_auth_token,
                has_auth_middleware,
                has_cors
            ])

            self.test_results.append({
                "validation": "security_implementation",
                "success": security_score >= 3,
                "security_score": security_score,
                "max_security_score": 4,
                "password_protection": has_password,
                "auth_token_initialized": has_auth_token,
                "auth_middleware_configured": has_auth_middleware,
                "cors_configured": has_cors
            })

        except Exception as e:
            print(f"  âŒ Security validation failed: {e}")
            self.test_results.append({
                "validation": "security_implementation",
                "success": False,
                "error": str(e)
            })

    async def validate_error_handling(self):
        """Validate error handling implementation"""
        print("\nâš ï¸ Validating Error Handling")

        try:
            dashboard = MonitoringDashboard(port=8099)

            # Check error handling patterns
            error_handling_checks = [
                ('logger', 'Logging system'),
                ('broadcast_to_clients', 'Error broadcasting'),
                ('send_to_client', 'Client error response'),
                ('cleanup', 'Resource cleanup')
            ]

            error_validation = []

            for attr_name, description in error_handling_checks:
                has_attr = hasattr(dashboard, attr_name)

                error_validation.append({
                    "component": description,
                    "success": has_attr,
                    "attribute": attr_name
                })

                status = "âœ…" if has_attr else "âŒ"
                print(f"  {status} {description} ({attr_name})")

            success_count = sum(1 for v in error_validation if v["success"])
            success_rate = (success_count / len(error_handling_checks)) * 100

            self.test_results.append({
                "validation": "error_handling",
                "success": success_rate >= 75,
                "success_rate": success_rate,
                "components_implemented": success_count,
                "total_components": len(error_handling_checks)
            })

        except Exception as e:
            print(f"  âŒ Error handling validation failed: {e}")
            self.test_results.append({
                "validation": "error_handling",
                "success": False,
                "error": str(e)
            })

    async def generate_validation_report(self):
        """Generate comprehensive validation report"""
        print("\n" + "=" * 60)
        print("ðŸ“‹ FUNCTIONALITY VALIDATION REPORT")
        print("=" * 60)

        total_validations = len(self.test_results)
        successful_validations = sum(1 for r in self.test_results if r.get("success", False))
        success_rate = (successful_validations / total_validations) * 100 if total_validations > 0 else 0

        print(f"\nðŸ“Š OVERALL VALIDATION RESULTS:")
        print(f"  Total Validations: {total_validations}")
        print(f"  Successful Validations: {successful_validations}")
        print(f"  Success Rate: {success_rate:.1f}%")

        print(f"\nðŸ“‹ VALIDATION BREAKDOWN:")
        for result in self.test_results:
            validation_name = result.get("validation", "Unknown")
            success = result.get("success", False)
            status = "âœ… PASS" if success else "âŒ FAIL"
            print(f"  {status} {validation_name}")

            # Add specific metrics
            if validation_name == "workflow_detection_logic":
                rate = result.get("success_rate", 0)
                print(f"      Detection Rate: {rate:.1f}%")
            elif validation_name == "workflow_templates":
                rate = result.get("success_rate", 0)
                print(f"      Template Validation: {rate:.1f}%")
            elif validation_name == "api_endpoint_definitions":
                rate = result.get("success_rate", 0)
                print(f"      Endpoint Coverage: {rate:.1f}%")
            elif validation_name == "enhanced_chat_structure":
                rate = result.get("method_success_rate", 0)
                print(f"      Method Implementation: {rate:.1f}%")
            elif validation_name == "navigation_system":
                rate = result.get("success_rate", 0)
                print(f"      Navigation Coverage: {rate:.1f}%")
            elif validation_name == "security_implementation":
                score = result.get("security_score", 0)
                max_score = result.get("max_security_score", 4)
                print(f"      Security Score: {score}/{max_score}")

        print(f"\nðŸ’¡ IMPLEMENTATION ASSESSMENT:")
        if success_rate >= 90:
            print("  âœ… EXCELLENT: Nearly all functionality implemented correctly!")
            print("  The enhanced dashboard is ready for production use.")
        elif success_rate >= 75:
            print("  ðŸŸ¡ GOOD: Most functionality implemented.")
            print("  Minor improvements needed for full functionality.")
        elif success_rate >= 50:
            print("  âš ï¸ FAIR: Basic functionality implemented.")
            print("  Significant improvements needed.")
        else:
            print("  âŒ POOR: Major functionality missing.")
            print("  Extensive development needed.")

        # Save detailed validation report
        validation_report = {
            "validation_run": self.validation_time,
            "total_validations": total_validations,
            "successful_validations": successful_validations,
            "success_rate": success_rate,
            "test_results": self.test_results,
            "implementation_status": "excellent" if success_rate >= 90 else "good" if success_rate >= 75 else "fair" if success_rate >= 50 else "poor"
        }

        report_file = f"validation_report_{int(time.time())}.json"
        with open(report_file, 'w') as f:
            json.dump(validation_report, f, indent=2)

        print(f"\nðŸ“„ Detailed validation report saved to: {report_file}")


async def main():
    """Main validation runner"""
    validator = FunctionalityValidator()
    await validator.run_all_validations()


if __name__ == "__main__":
    asyncio.run(main())